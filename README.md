# VisionTransformer_from_scratch
The model architecture consists of several layers, including Transformer encoders, linear projections, and attention heads:

### Total Parameters
- **Total Parameters:** 20,236,810
- **Trainable Parameters:** 20,236,810
- **Non-trainable Parameters:** 0
